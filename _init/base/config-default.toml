# >>> DO NOT EDIT THIS FILE <<<

# IMPORTANT: THIS FILE WILL BE UPDATED WITH EACH AIPACK UPDATE

# To customize AIPACK, edit the sibling `./config-user.toml` with the values to add or override. 

# Thus, `config-default.toml` will be loaded first, and `config-user.toml` will be merged on top of it to create the 
# global configuration for aipack. This can then be overridden by the workspace `.aipack/config.toml` and agent-specific options. 

[options]

# `model` is required to run an agent. 
#         This will be the fallback if not defined in `./config-user.toml` or a workspace-level `config.toml`.
#
# Supported models from:
#   - OpenAI, Gemini, Anthropic, Ollama (local), xAI, Cohere, DeepSeek, 
#   - Fireworks.Ai, Nebius, Groq, Together.ai
#
# e.g.,  
#    OpenAI: `"gpt-4.1"`, `"gpt-4.1-mini"`, `"gpt-4.1-nano"`, `"o4-mini"` (with optional `-low`, `-medium`, `-high` suffixes)
#    Gemini: `"gemini-2.5-pro"`, `"gemini-2.5-flash"`, `"gemini-2.5-flash-zero"` (with `-zero`, `-low`, `-medium`, `-high` suffixes)
# Anthropic: `"claude-sonnet-4-20250514"`, `"claude-3-5-haiku-latest"`
# Fireworks: `"fireworks::qwen3-coder-480b-a35b-instruct"`, `"fireworks::kimi-k2-instruct"`, or full name `accounts/fireworks/models/qwen3-235b-a22b-thinking-2507`
#    Ollama: `"phi4:14b"`, `"gemma3:4b"`, `"gemma3:27b"`, `"deepseek-r1:70b"`, `"llama4:scout"` (or any locally installed Ollama)

model = "gpt-4.1-mini" # or an alias from below (e.g., "flash", "gpro")

# Temperature (by default unset)

# temperature = 0.0

# How many inputs can be processed at the same time (Defaults to 2 if absent)

input_concurrency = 2

# Model Aliases
#
# These are default model aliases that can be used. 
#
# These will be updated over time as versions are updated. 
#
# Customize global model aliases in `./config-user.toml`.
#
# Recommendation: Use simple alias names with `_` and `-` (like those below or in `config-default.toml`). 
#
# Note 1: If an alias name contains `.` or special characters, use double quotes. 
#         e.g., `"my-4.1" = "gpt-4.1-nano"`
#
# Note 2: Aliases can be added or overridden in the workspace `.aipack/config.toml` or via agent options.
#
[options.model_aliases]
# -- Anthropic
claude        = "claude-sonnet-4-20250514"
# -- OpenAI
# For OpenAI, model names can use `-high`, `-medium`, or `-low` suffixes.
#             e.g., `o3-low`, `o4-mini-high`
gpt           = "gpt-4.1"
gpt-mini      = "gpt-4.1-mini"
gpt-nano      = "gpt-4.1-nano"
# -- Google
# As shown below, Gemini model names also support the use of `-high`, `-medium`, or `-low` suffixes,
# in addition to the `-zero` suffix for Flash 2.5
gpro          = "gemini-2.5-pro"
gpro-low      = "gemini-2.5-pro-low"
gpro-medium   = "gemini-2.5-pro-medium"
gpro-high     = "gemini-2.5-pro-high"
flash         = "gemini-2.5-flash"
flash-zero    = "gemini-2.5-flash-zero"
flash-low     = "gemini-2.5-flash-low"
flash-medium  = "gemini-2.5-flash-medium"
flash-high    = "gemini-2.5-flash-high"
lite          = "gemini-2.5-flash-lite-preview-06-17"
# -- Fireworks (namespaced with `fireworks::_model_name`
qwen-coder    = "fireworks::qwen3-coder-480b-a35b-instruct"
qwen          = "fireworks::qwen3-235b-a22b-instruct-2507"
qwen-thinker  = "accounts/fireworks/models/qwen3-235b-a22b-thinking-2507" # can be full fireworks name
kimi          = "fireworks::kimi-k2-instruct"
glm           = "fireworks::glm-4p5"
glm-air       = "fireworks::glm-4p5-air"
# -- DeepSeek (from deepseek.com)
r1            = "deepseek-reasoner"
