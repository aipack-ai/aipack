# This `.aipack/config.toml` file overrides the base `~/.aipack-base/config.toml`.
# Any property from the base config.toml can be overridden here for this workspace (the workspace is the parent directory of this .aipack/ directory).

# Note: Was `default_options` in `<= 0.7.9` (both still supported, but now use 'options')
[options]

# `model` is required (any model supported by the Rust genai crate)
#         By default, it is set in the `~/.aipack-base/config.toml`, but it can be overridden here,
#         as with any other properties.
#
# Support models from: OpenAI, Gemini, Anthropic, Ollama (local), DeepSeek, Groq, Grok(xAI)
#
# e.g.,  
#    Ollama: "phi4:14b", "gemma3:4b", "gemma3:27b", "deepseek-r1:70b", "llama4:scout" (or any locally installed Ollama)
# Anthropic: "claude-sonnet-4-20250514", "claude-3-5-haiku-latest"
#    OpenAI: "gpt-4.1, "gpt-4.1-mini", "gpt-4.1-nano", "o4-mini", "o4-mini-high", "o4-mini-low"
#    Gemini: "gemini-2.5-pro-preview-06-05", "gemini-2.5-flash-preview-05-20", "gemini-2.5-flash-preview-05-20-zero"

# model = "gpt-4.1-mini" # or an alias from below (e.g., "flash-prev", "gpro-prev")

# Temperature - by default unset

# temperature = 0.0

# Concurrency - How many inputs can be processed at the same time
# (Set to 2 in the default ~/.aipack-base/config.toml if absent)

# input_concurrency = 6

# Model Aliases - or override model aliases
# The ones below are already configured in the ~/.aipack-base/config.toml
# However, you can add new aliases or override them below (in this workspace config.toml). 
#
# [options.model_aliases]
# # -- Anthropic
# claude      = "claude-sonnet-4-20250514"
# # -- OpenAI
# high        = "o4-mini-high"
# med         = "o4-mini"
# low         = "o4-mini-low"
# main        = "gpt-4.1"
# mini        = "gpt-4.1-mini"
# nano        = "gpt-4.1-nano"
# # -- Google
# gpro-prev       = "gemini-2.5-pro-preview-06-05"
# flash           = "gemini-2.0-flash"
# flash-prev      = "gemini-2.5-flash-preview-05-20"
# flash-prev-zero = "gemini-2.5-flash-preview-05-20-zero"
# # -- Deepseek
# r1          = "deepseek-reasoner"
