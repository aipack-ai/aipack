use crate::run::pricing::{ModelPricing, ProviderPricing};

pub const TOGETHER_MODELS: &[ModelPricing] = &[
	ModelPricing {
		name: "deepcogito/cogito-v2-preview-deepseek-671b",
		input_cached: None,
		input_normal: 1.25,
		output_normal: 1.25,
		output_reasoning: None,
	},
	ModelPricing {
		name: "deepseek-ai/deepseek-r1",
		input_cached: None,
		input_normal: 3.0,
		output_normal: 7.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "deepseek-ai/deepseek-r1-0528-tput",
		input_cached: None,
		input_normal: 0.55,
		output_normal: 2.19,
		output_reasoning: None,
	},
	ModelPricing {
		name: "deepseek-ai/deepseek-r1-distill-llama-70b",
		input_cached: None,
		input_normal: 2.0,
		output_normal: 2.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "deepseek-ai/deepseek-r1-distill-qwen-1.5b",
		input_cached: None,
		input_normal: 0.18,
		output_normal: 0.18,
		output_reasoning: None,
	},
	ModelPricing {
		name: "deepseek-ai/deepseek-r1-distill-qwen-14b",
		input_cached: None,
		input_normal: 1.6,
		output_normal: 1.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "deepseek-ai/deepseek-v3",
		input_cached: None,
		input_normal: 1.25,
		output_normal: 1.25,
		output_reasoning: None,
	},
	ModelPricing {
		name: "google/gemma-2-27b-it",
		input_cached: None,
		input_normal: 0.8,
		output_normal: 0.8,
		output_reasoning: None,
	},
	ModelPricing {
		name: "google/gemma-3n-e4b-it",
		input_cached: None,
		input_normal: 0.02,
		output_normal: 0.04,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/llama-2-70b-hf",
		input_cached: None,
		input_normal: 0.9,
		output_normal: 0.9,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/llama-3-70b-chat-hf",
		input_cached: None,
		input_normal: 0.88,
		output_normal: 0.88,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/llama-3-8b-chat-hf",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/llama-3.2-3b-instruct-turbo",
		input_cached: None,
		input_normal: 0.06,
		output_normal: 0.06,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/llama-3.3-70b-instruct-turbo",
		input_cached: None,
		input_normal: 0.88,
		output_normal: 0.88,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/llama-4-maverick-17b-128e-instruct-fp8",
		input_cached: None,
		input_normal: 0.27,
		output_normal: 0.85,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/llama-4-scout-17b-16e-instruct",
		input_cached: None,
		input_normal: 0.18,
		output_normal: 0.59,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/meta-llama-3-70b-instruct-turbo",
		input_cached: None,
		input_normal: 0.88,
		output_normal: 0.88,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/meta-llama-3-8b-instruct-lite",
		input_cached: None,
		input_normal: 0.1,
		output_normal: 0.1,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/meta-llama-3.1-405b-instruct-turbo",
		input_cached: None,
		input_normal: 3.5,
		output_normal: 3.5,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/meta-llama-3.1-70b-instruct-turbo",
		input_cached: None,
		input_normal: 0.88,
		output_normal: 0.88,
		output_reasoning: None,
	},
	ModelPricing {
		name: "meta-llama/meta-llama-3.1-8b-instruct-turbo",
		input_cached: None,
		input_normal: 0.18,
		output_normal: 0.18,
		output_reasoning: None,
	},
	ModelPricing {
		name: "mistralai/mistral-7b-instruct-v0.1",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "mistralai/mistral-7b-instruct-v0.2",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "mistralai/mistral-7b-instruct-v0.3",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "mistralai/mistral-small-24b-instruct-2501",
		input_cached: None,
		input_normal: 0.8,
		output_normal: 0.8,
		output_reasoning: None,
	},
	ModelPricing {
		name: "mistralai/mixtral-8x7b-instruct-v0.1",
		input_cached: None,
		input_normal: 0.6,
		output_normal: 0.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "nousresearch/nous-hermes-2-mixtral-8x7b-dpo",
		input_cached: None,
		input_normal: 0.6,
		output_normal: 0.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "nvidia/llama-3.1-nemotron-70b-instruct-hf",
		input_cached: None,
		input_normal: 0.88,
		output_normal: 0.88,
		output_reasoning: None,
	},
	ModelPricing {
		name: "openai/gpt-oss-120b",
		input_cached: None,
		input_normal: 0.15,
		output_normal: 0.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "openai/gpt-oss-20b",
		input_cached: None,
		input_normal: 0.05,
		output_normal: 0.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwq-32b",
		input_cached: None,
		input_normal: 1.2,
		output_normal: 1.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen2-72b-instruct",
		input_cached: None,
		input_normal: 0.9,
		output_normal: 0.9,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen2-vl-72b-instruct",
		input_cached: None,
		input_normal: 1.2,
		output_normal: 1.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen2.5-72b-instruct-turbo",
		input_cached: None,
		input_normal: 1.2,
		output_normal: 1.2,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen2.5-7b-instruct-turbo",
		input_cached: None,
		input_normal: 0.3,
		output_normal: 0.3,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen2.5-vl-72b-instruct",
		input_cached: None,
		input_normal: 1.95,
		output_normal: 8.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen3-235b-a22b-fp8-tput",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen3-235b-a22b-instruct-2507-tput",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 0.6,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen3-235b-a22b-thinking-2507",
		input_cached: None,
		input_normal: 0.65,
		output_normal: 3.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "qwen/qwen3-coder-480b-a35b-instruct-fp8",
		input_cached: None,
		input_normal: 2.0,
		output_normal: 2.0,
		output_reasoning: None,
	},
	ModelPricing {
		name: "zai-org/glm-4.5-air-fp8",
		input_cached: None,
		input_normal: 0.2,
		output_normal: 1.1,
		output_reasoning: None,
	},
];

pub const TOGETHER: ProviderPricing = ProviderPricing {
	name: "together",
	models: TOGETHER_MODELS,
};
