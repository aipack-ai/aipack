[default_options]
# Required (any model supported by the Rust genai crate)
# e.g.,    
#             xAI: "grok-beta"
#       Anthropic: "claude-sonnet-4-20250514"
#          Gemini: "gemini-2.5-flash"
#          Ollama: "llama3.3:70b", "llama3.1:8b", "llama3.2:3b" "deepseek-r1:8b" "deepseek-coder-v2:16b" (or any locally installed Ollama)
#            Groq: "deepseek-r1-distill-llama-70b", "llama3-8b-8192", "llama-3.3-70b-versatile"
#          OpenAI: "gpt-5", "gpt-5-low"
#        DeepSeek: "deepseek-chat" "deepseek-reasoner" (from deepseek.com)
model = "gpt-5-mini"

# Temperature (by default unset)
temperature = 0.0

# How many inputs can be processed at the same time
# (Defaults to 1 if absent)
input_concurrency = 6

model_aliases = { small = "gemini-2.5-flash", standard = "gpt-5", coder = "gpt-5", reasoner = "gpt-5-high" }


